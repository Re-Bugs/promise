{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# medicines",
   "id": "4b3a0dd1f5e9e930"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-20T06:45:08.939722Z",
     "start_time": "2024-09-20T06:45:08.426505Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "csv_file_path = '/Users/seungwook/Downloads/약품코드.csv'  # 원본 CSV 파일 경로\n",
    "cleaned_file_path = '/Users/seungwook/Downloads/약품코드_1차.csv'  # 1차 전처리(제품코드만 있는 CSV 파일 경로)\n",
    "output_file_path = '/Users/seungwook/Downloads/약품코드_2차.csv'  # 2차 전처리(1차 전처리 파일에서 중복 제거)\n",
    "sql_file_path = '/Users/seungwook/Downloads/medicines_insert.sql'  # medicines 테이블에 삽입 쿼리\n",
    "\n",
    "# 1차 전처리: UTF-8 인코딩으로 파일 읽기\n",
    "df = pd.read_csv(csv_file_path, encoding='utf-8', dtype={'product_code': str})  # product_code를 문자열로 읽음\n",
    "df_cleaned = df[df['product_code'].notnull()]  # product_code가 null이 아닌 경우만 필터링\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False, encoding='utf-8')  # 1차 전처리 파일 저장\n",
    "\n",
    "# 2차 전처리: 중복 제거 후 저장\n",
    "df = pd.read_csv(cleaned_file_path, encoding='utf-8', dtype={'product_code': str})\n",
    "df_unique = df.drop_duplicates(subset='product_code')  # product_code 기준 중복 제거\n",
    "df_unique.to_csv(output_file_path, index=False, encoding='utf-8')  # 2차 전처리 파일 저장\n",
    "\n",
    "# medicines 테이블에 삽입할 SQL 쿼리 생성\n",
    "df_medicines = pd.read_csv(output_file_path, encoding='utf-8', dtype={'product_code': str})\n",
    "\n",
    "# product_code가 8자리인 경우 맨 앞에 0을 추가하여 9자리로 변환\n",
    "df_medicines['product_code'] = df_medicines['product_code'].apply(\n",
    "    lambda x: f\"'{x.zfill(9)}'\" if pd.notnull(x) and len(x) == 8 else f\"'{x}'\" if pd.notnull(x) else 'NULL'\n",
    ")\n",
    "\n",
    "# 각 컬럼값이 null인 경우 처리\n",
    "df_medicines['category'] = df_medicines['category'].apply(lambda x: f\"'{x}'\" if pd.notnull(x) else 'NULL')\n",
    "df_medicines['manufacturer'] = df_medicines['manufacturer'].apply(lambda x: f\"'{x}'\" if pd.notnull(x) else 'NULL')\n",
    "\n",
    "# SQL 쿼리 생성\n",
    "sql_statements = []\n",
    "for index, row in df_medicines.iterrows():\n",
    "    name = row['name'].replace(\"'\", \"''\")  # 작은따옴표 이스케이프 처리\n",
    "    product_code = row['product_code']\n",
    "    category = row['category']\n",
    "    manufacturer = row['manufacturer']\n",
    "    sql = f\"INSERT INTO medicines (name, product_code, category, manufacturer) \" \\\n",
    "          f\"VALUES ('{name}', {product_code}, {category}, {manufacturer});\"\n",
    "    sql_statements.append(sql)\n",
    "\n",
    "# SQL 파일 생성 및 저장\n",
    "with open(sql_file_path, 'w', encoding='utf-8') as f:\n",
    "    for statement in sql_statements:\n",
    "        f.write(statement + '\\n')"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SQL 파일이 생성되었습니다: /Users/seungwook/Downloads/medicines_insert.sql\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DUR",
   "id": "fd028a6fff73e390"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T15:31:09.684736Z",
     "start_time": "2024-09-15T15:31:03.765421Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dur_file_path = '/Users/seungwook/Downloads/DUR.csv' #원본\n",
    "cleaned_dur_file_path = '/Users/seungwook/Downloads/DUR_중복제거.csv' #중복제거\n",
    "sql_output_path = '/Users/seungwook/Downloads/dur_insert.sql' #dur 테이블에 삽입쿼리(여기서 실제 medicines 테이블에 존재하는 product_code만 삽입 쿼리가 생성됨)\n",
    "\n",
    "\n",
    "# DUR 파일 중복 데이터 제거\n",
    "import pandas as pd\n",
    "df_dur = pd.read_csv(dur_file_path, encoding='euc-kr')\n",
    "df_dur_unique = df_dur.drop_duplicates()\n",
    "df_dur_unique.to_csv(cleaned_dur_file_path, index=False, encoding='euc-kr')\n",
    "\n",
    "# dur_insert.sql(여기서 실제 medicines 테이블에 존재하는 product_code만 삽입 쿼리가 생성됨)\n",
    "medicines_file_path = output_file_path\n",
    "dur_file_path = cleaned_dur_file_path\n",
    "df_dur = pd.read_csv(dur_file_path, encoding='euc-kr')\n",
    "df_medicines = pd.read_csv(medicines_file_path, encoding='euc-kr')\n",
    "df_filtered_dur = df_dur[\n",
    "    (df_dur['a_product_code'].isin(df_medicines['product_code'])) & \n",
    "    (df_dur['b_product_code'].isin(df_medicines['product_code']))\n",
    "]\n",
    "sql_statements = []\n",
    "for _, row in df_filtered_dur.iterrows():\n",
    "    a_product_code = row['a_product_code']\n",
    "    b_product_code = row['b_product_code']\n",
    "    reason = str(row['reason']).replace(\"'\", \"''\") if pd.notnull(row['reason']) else 'NULL'\n",
    "    etc = \"'\" + str(row['etc']).replace(\"'\", \"''\") + \"'\" if pd.notnull(row['etc']) else 'NULL'\n",
    "    sql = f\"INSERT INTO dur (a_product_code, b_product_code, reason, etc) \" \\\n",
    "          f\"VALUES ('{a_product_code}', '{b_product_code}', '{reason}', {etc});\"\n",
    "    sql_statements.append(sql)\n",
    "with open(sql_output_path, 'w') as f:\n",
    "    for statement in sql_statements:\n",
    "        f.write(statement + '\\n')"
   ],
   "id": "bda90235c7986324",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# clinic_location",
   "id": "a0acaf954a1aa671"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T15:43:16.144910Z",
     "start_time": "2024-09-15T15:43:15.792054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "clinic_data_path = '/Users/seungwook/Downloads/의료시설.csv'  # CSV 파일 경로\n",
    "result_file = '/Users/seungwook/Downloads/clinic_location_insert.sql'  # SQL 파일 저장 경로\n",
    "\n",
    "clinic_data = pd.read_csv(clinic_data_path, encoding='euc-kr')\n",
    "def generate_sql(row):\n",
    "    return f\"\"\"\n",
    "    INSERT INTO clinic_location (district_name, type, name, inpatient_room, hospital_bed, tel, address, longitude, latitude)\n",
    "    VALUES ('{row['district_name']}', '{row['type']}', '{row['name']}', {row['inpatient_room']}, {row['hospital_bed']}, '{row['tel']}', '{row['address']}', {row['longitude']}, {row['latitude']});\n",
    "    \"\"\"\n",
    "sql_statements = [generate_sql(row) for index, row in clinic_data.iterrows()]\n",
    "with open(result_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\n\".join(sql_statements))"
   ],
   "id": "75eb09de230a3722",
   "outputs": [],
   "execution_count": 3
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
