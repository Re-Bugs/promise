{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# medicines",
   "id": "4b3a0dd1f5e9e930"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T12:38:12.287164Z",
     "start_time": "2024-09-29T12:38:11.708708Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "csv_file_path = '/Users/seungwook/Downloads/약품코드.csv'  # 원본 CSV 파일 경로\n",
    "cleaned_file_path = '/Users/seungwook/Downloads/약품코드_1차.csv'  # 1차 전처리(제품코드만 있는 CSV 파일 경로)\n",
    "output_file_path = '/Users/seungwook/Downloads/약품코드_2차.csv'  # 2차 전처리(1차 전처리 파일에서 중복 제거)\n",
    "sql_file_path = '/Users/seungwook/Downloads/medicines_insert.sql'  # medicines 테이블에 삽입 쿼리\n",
    "\n",
    "# 1차 전처리: UTF-8 인코딩으로 파일 읽기\n",
    "df = pd.read_csv(csv_file_path, encoding='utf-8', dtype={'product_code': str})  # product_code를 문자열로 읽음\n",
    "df_cleaned = df[df['product_code'].notnull()]  # product_code가 null이 아닌 경우만 필터링\n",
    "df_cleaned.to_csv(cleaned_file_path, index=False, encoding='utf-8')  # 1차 전처리 파일 저장\n",
    "\n",
    "# 2차 전처리: 중복 제거 후 저장\n",
    "df = pd.read_csv(cleaned_file_path, encoding='utf-8', dtype={'product_code': str})\n",
    "df_unique = df.drop_duplicates(subset='product_code')  # product_code 기준 중복 제거\n",
    "df_unique.to_csv(output_file_path, index=False, encoding='utf-8')  # 2차 전처리 파일 저장\n",
    "\n",
    "# medicines 테이블에 삽입할 SQL 쿼리 생성\n",
    "df_medicines = pd.read_csv(output_file_path, encoding='utf-8', dtype={'product_code': str})\n",
    "\n",
    "# product_code가 8자리인 경우 맨 앞에 0을 추가하여 9자리로 변환\n",
    "df_medicines['product_code'] = df_medicines['product_code'].apply(\n",
    "    lambda x: f\"'{x.zfill(9)}'\" if pd.notnull(x) and len(x) == 8 else f\"'{x}'\" if pd.notnull(x) else 'NULL'\n",
    ")\n",
    "\n",
    "# 각 컬럼값이 null인 경우 처리\n",
    "df_medicines['category'] = df_medicines['category'].apply(lambda x: f\"'{x}'\" if pd.notnull(x) else 'NULL')\n",
    "df_medicines['manufacturer'] = df_medicines['manufacturer'].apply(lambda x: f\"'{x}'\" if pd.notnull(x) else 'NULL')\n",
    "\n",
    "# SQL 쿼리 생성\n",
    "sql_statements = []\n",
    "for index, row in df_medicines.iterrows():\n",
    "    name = row['name'].replace(\"'\", \"''\")  # 작은따옴표 이스케이프 처리\n",
    "    product_code = row['product_code']\n",
    "    category = row['category']\n",
    "    manufacturer = row['manufacturer']\n",
    "    sql = f\"INSERT INTO medicines (name, product_code, category, manufacturer) \" \\\n",
    "          f\"VALUES ('{name}', {product_code}, {category}, {manufacturer});\"\n",
    "    sql_statements.append(sql)\n",
    "\n",
    "# SQL 파일 생성 및 저장\n",
    "with open(sql_file_path, 'w', encoding='utf-8') as f:\n",
    "    for statement in sql_statements:\n",
    "        f.write(statement + '\\n')"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# DUR",
   "id": "fd028a6fff73e390"
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-09-29T13:09:27.484209Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 설정\n",
    "dur_file_path = '/Users/seungwook/Downloads/DUR.csv'  # 원본 DUR 파일\n",
    "medicines_file_path = '/Users/seungwook/Downloads/약품코드_2차.csv'  # medicines 테이블의 CSV 파일 경로\n",
    "sql_output_path = '/Users/seungwook/Downloads/dur_insert.sql'  # SQL 삽입 쿼리 경로\n",
    "error_log_path = '/Users/seungwook/Downloads/error_log.txt'  # 오류 로그 파일 경로\n",
    "\n",
    "# DUR 파일과 medicines 테이블 데이터를 읽어옴\n",
    "df_dur = pd.read_csv(dur_file_path, encoding='euc-kr')\n",
    "df_medicines = pd.read_csv(medicines_file_path, encoding='utf-8')\n",
    "\n",
    "# a_product_code와 b_product_code가 8자리일 경우 9자리로 변환하는 방식 (f-string)\n",
    "def format_code_to_9_digits(code):\n",
    "    if isinstance(code, (int, float)):  # 숫자일 경우 처리\n",
    "        code_str = f\"{int(code):09d}\"  # 9자리로 맞춰서 변환\n",
    "    elif isinstance(code, str) and len(code) == 8:  # 8자리 문자열일 경우 앞에 '0' 추가\n",
    "        code_str = f\"0{code}\"\n",
    "    else:\n",
    "        code_str = code  # 변환할 필요 없는 경우 그대로 유지\n",
    "    return code_str\n",
    "\n",
    "# a_product_code와 b_product_code 변환\n",
    "df_dur['a_product_code'] = df_dur['a_product_code'].apply(format_code_to_9_digits)\n",
    "df_dur['b_product_code'] = df_dur['b_product_code'].apply(format_code_to_9_digits)\n",
    "\n",
    "# DUR 파일과 medicines 테이블 불일치 코드 추출 및 로그\n",
    "df_medicines['product_code'] = df_medicines['product_code'].astype(str).str.strip()\n",
    "\n",
    "# a_product_code와 b_product_code가 medicines 테이블에 없는 경우 로그 기록\n",
    "invalid_a_codes = df_dur[~df_dur['a_product_code'].isin(df_medicines['product_code'])]\n",
    "invalid_b_codes = df_dur[~df_dur['b_product_code'].isin(df_medicines['product_code'])]\n",
    "\n",
    "with open(error_log_path, 'w', encoding='utf-8') as log_file:\n",
    "    if not invalid_a_codes.empty:\n",
    "        log_file.write(\"Invalid a_product_codes:\\n\")\n",
    "        log_file.write(invalid_a_codes.to_string(index=False))\n",
    "    if not invalid_b_codes.empty:\n",
    "        log_file.write(\"\\n\\nInvalid b_product_codes:\\n\")\n",
    "        log_file.write(invalid_b_codes.to_string(index=False))\n",
    "\n",
    "# a_product_code와 b_product_code가 medicines 테이블에 있는 경우만 필터링\n",
    "df_filtered_dur = df_dur[\n",
    "    df_dur['a_product_code'].isin(df_medicines['product_code']) & \n",
    "    df_dur['b_product_code'].isin(df_medicines['product_code'])\n",
    "]\n",
    "\n",
    "# SQL 삽입문 생성\n",
    "sql_statements = []\n",
    "for _, row in df_filtered_dur.iterrows():\n",
    "    a_product_code = row['a_product_code']\n",
    "    b_product_code = row['b_product_code']\n",
    "    reason = str(row['reason']).replace(\"'\", \"''\") if pd.notnull(row['reason']) else 'NULL'\n",
    "    etc = \"'\" + str(row['etc']).replace(\"'\", \"''\") + \"'\" if pd.notnull(row['etc']) else 'NULL'\n",
    "    \n",
    "    sql = f\"INSERT INTO dur (a_product_code, b_product_code, reason, etc) \" \\\n",
    "          f\"VALUES ('{a_product_code}', '{b_product_code}', '{reason}', {etc});\"\n",
    "    sql_statements.append(sql)\n",
    "\n",
    "# SQL 파일에 작성\n",
    "with open(sql_output_path, 'w', encoding='utf-8') as f:\n",
    "    for statement in sql_statements:\n",
    "        f.write(statement + '\\n')\n"
   ],
   "id": "bda90235c7986324",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# clinic_location",
   "id": "a0acaf954a1aa671"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-15T15:43:16.144910Z",
     "start_time": "2024-09-15T15:43:15.792054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "clinic_data_path = '/Users/seungwook/Downloads/의료시설.csv'  # CSV 파일 경로\n",
    "result_file = '/Users/seungwook/Downloads/clinic_location_insert.sql'  # SQL 파일 저장 경로\n",
    "\n",
    "clinic_data = pd.read_csv(clinic_data_path, encoding='euc-kr')\n",
    "def generate_sql(row):\n",
    "    return f\"\"\"\n",
    "    INSERT INTO clinic_location (district_name, type, name, inpatient_room, hospital_bed, tel, address, longitude, latitude)\n",
    "    VALUES ('{row['district_name']}', '{row['type']}', '{row['name']}', {row['inpatient_room']}, {row['hospital_bed']}, '{row['tel']}', '{row['address']}', {row['longitude']}, {row['latitude']});\n",
    "    \"\"\"\n",
    "sql_statements = [generate_sql(row) for index, row in clinic_data.iterrows()]\n",
    "with open(result_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"\\n\".join(sql_statements))"
   ],
   "id": "75eb09de230a3722",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T12:03:44.456550Z",
     "start_time": "2024-09-29T12:03:10.734054Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import chardet\n",
    "\n",
    "with open(dur_file_path, 'rb') as f:\n",
    "    result = chardet.detect(f.read())\n",
    "    print(result)"
   ],
   "id": "6de8a8a036758e4f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'encoding': 'EUC-KR', 'confidence': 0.99, 'language': 'Korean'}\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
